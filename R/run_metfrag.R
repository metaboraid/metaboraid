#' Perform identification using Metfrag
#'
#' This function allows you to perform identification using Metfrag
#' Please note that you need to have Metfrag, e.g using \code{\link{install_tools}}
#'
#' We install Metfrag in metaboraid_package environment.
#'
#'
#'
#' @param parameter_zip_files A zip file containing MS2 parameter generated by \code{\link{map_adducts}}
#' @param database Name of the database to use: Only one of KEGG, PubChem, ChemSpider, and LocalCSV!
#' @param local_database absolute path to the local database (CSV). See the details
#' @param ncores Number of cores to use for parallel processing. Default 1
#' @param progress_bar Whether to show progress bar or not. Default FALSE
#' @param verbose Show information about different stages of the processes. Default FALSE
#' @param conda Conda binary to use. Default auto
#' @param env conda environment used to run the process. Default metaboraid_package
#' @param results_folder a path to a folder where results for EACH ion will be returned
#' @param chech_file_interval not used
#' @param total_check_time not used
#' @param timeout The maximum number of seconds to wait for a single out to give a result. Default 600
#' @export
#' @details The local CSV file must contain the metabolites you wish to perform identification on.
#' this file must contain the following columns: "Identifier",  "MonoisotopicMass" ,"MolecularFormula" ,"SMILES"        ,   "InChI"         ,   "InChIKey1"     ,   "InChIKey2"    ,    "InChIKey3"    ,    "Name"         ,    "InChIKey".
#' An example of such dataset for HMDB can be found here: \url{https://github.com/metaboraid/test-datasets/blob/master/hmdb_2017-07-23.csv}
#'
#' @examples
#' library(CAMERA)
#' library(metaboraid)
#' # Read MS1 and MS2 files
#' ms1_files<-system.file("ms1data",c("X1_Rep1.mzML","X2_Rep1.mzML"),package = "metaboraid")
#' ms2_files<-system.file("ms2data",c("sample1.mzML","sample2.mzML"),package = "metaboraid")
#'
#' # mass trace detection
#' xs <- xcmsSet(ms1_files,method="centWave",ppm=30,peakwidth=c(5,10))
#'
#' # mass trace matching
#' xsg <- group(xs)
#'
#' # convert to CAMERA
#' xsa <- xsAnnotate(xsg)
#'
#' # Group mass traces
#' anF <- groupFWHM(xsa, perfwhm = 0.6)
#'
#' # Detect isotopes
#' anI <- findIsotopes(anF, mzabs = 0.01)
#'
#' # Group using correlation
#' anIC <- groupCorr(anI, cor_eic_th = 0.75)
#'
#' # Find adducts
#' anFA <- findAdducts(anIC, polarity="positive")
#'
#' # map features and MS2s
#' mapped_features<-map_features(inputMS2s = ms2_files,input_camera = anFA,ppm = 10,rt = 10)
#'
#' # Map adducts
#' mapped_adducts<-map_adducts(inputMS2List=mapped_features,input_camera=anFA,
#'                             precursorppm=10,
#'                             fragmentppm=20,fragmentabs=0.01,minPrecursorMass=NA,maxPrecursorMass=NA,
#'                             minPeaks=10,maxSpectra=10,mode="pos",adductRules="primary",
#'                             outputDir="general_parameters_4",searchMultipleChargeAdducts=T,
#'                             includeMapped=T,includeUnmapped=F,verbose=T)
#'
#' # Run the search
#'
#' run_metfrag("parameter_files.zip",database = "KEGG",ncores = 2,progress_bar = F,verbose = T,results_folder = "pp",chech_file_interval = 2,timeout = 600,conda = "auto")
#'
#' @return
#' A dataframe containing the identified ions. The dataframe contains search engine and database specific information but also tree important columns: parentMZ, parentRT, fileName which are used to trace the ions by the downstream processes.
#' @import reticulate
#' @import zip
#' @import parallel
#' @import future
#' @import progressr
#' @import future.apply
#'
run_metfrag<-function(parameter_zip_files=NA,database=NA,local_database=NA,ncores=1,progress_bar=T,verbose=F,conda = "auto",env="metaboraid_package",results_folder=NA,
                      chech_file_interval=2,total_check_time=20,timeout=600){
  if(verbose)cat("\nChecking software ...","\n")
  check_if_conda_is_installed(env,conda=conda)
  check_out<-suppressWarnings(check_if_software_exist("metfrag",conda=conda))
  if(length(check_out)==1 && check_out==1)
  {
    stop("We did not find metfrag! Please try installing the tools first!")
  }

  conda_path<-reticulate::conda_binary(conda)

  main_params<-c("run","-n",env)
  if(verbose)cat("\nChecking database ...","\n")
if(!database%in%c("KEGG","PubChem","ChemSpider","LocalCSV"))
{
  stop("The database must be one of KEGG, PubChem, ChemSpider, and LocalCSV!")
}

local_db<-""
if(database=="LocalCSV")
{
  if(is.na(local_database))stop("When use database=LocalCSV, you need to provide a path to a CSV dataset")
  if(!file.exists(local_database)){
    stop(sprintf("We did not find %s! Please check the path!",local_database))
  }

  tmp<-read.csv(local_database)
  data_Base_col_names<-c( "Identifier",  "MonoisotopicMass" ,"MolecularFormula" ,"SMILES"        ,   "InChI"         ,   "InChIKey1"     ,   "InChIKey2"    ,    "InChIKey3"    ,    "Name"         ,    "InChIKey" )
  if(!all(data_Base_col_names%in%colnames(tmp))){

    stop(sprintf("The following columns are missing from your database file: %s!",paste(data_Base_col_names[!data_Base_col_names%in%colnames(tmp)],collapse = ",")))
  }
  local_db<-paste("LocalDatabasePath=",local_database,sep = "")

}

if(is.na(parameter_zip_files) | is.null(parameter_zip_files))
{
  stop("parameter_zip_files is missing!")
}else{
 if(!file.exists(parameter_zip_files)){
   stop(sprintf("We could not find %s! Check parameter_zip_files!",parameter_zip_files))
 }
}


if(verbose)cat("\nPreparing metfrag ...","\n")


tmpDir<-createTmpDir("metfrag_")
do.call(file.remove, list(list.files(tmpDir, full.names = TRUE,recursive = T)))
zip::unzip(parameter_zip_files,junkpaths = T,exdir = tmpDir)
all_params<-list.files(tmpDir,full.names = T)


tmpDir2<-tmpDir
outDir<-paste(tmpDir2,"metfrag_res",sep = "/")
dir.create(outDir)
library(doFuture)
if(is.na(ncores)|is.null(ncores))
{
  stop("ncores must be a number higher than 1!")
}
if(ncores>1)
{
  if(verbose)cat("Running metfrag in parallel...","\n")
  cl <- parallel::makeCluster(ncores, type = "PSOCK")
  plan(future::cluster, workers = cl)
}else{
  if(verbose)cat("Running metfrag sequencial ...","\n")
  plan(sequential)
}

if(!is.numeric(timeout))
{
  stop("timeout must be numberic!")
}else if(timeout<0){
  stop("timeout must be equal or greater than than 0!")
}

if(!is.numeric(chech_file_interval))
{
  stop("chech_file_interval must be numberic!")
}else if(chech_file_interval<0){
  stop("chech_file_interval must be equal or greater than than 0!")
}
if(timeout<=chech_file_interval)
{
  stop("timeout must be greater than chech_file_interval!")
}

if(is.na(progress_bar) | is.null(progress_bar))
{
  stop("progress_bar must be a logical value!")
}
if(!is.logical(progress_bar))
{
  stop("progress_bar must be a logical value!")
}
#
# if(!is.numeric(total_check_time))
# {
#   stop("total_check_time must be numberic!")
# }else if(total_check_time<0){
#   stop("total_check_time must be equal or greater than than 0!")
# }


results<-NA
if(!is.na(results_folder))
{
  dir.create(results_folder)
}

if(progress_bar==TRUE)
  p <- progressr::progressor(along =  all_params)

  library(future.apply)
  results<-  future_lapply(all_params,function(par_file) {



  command_metfrag<-readLines(par_file)
  command_metfrag<-paste(command_metfrag,"MetFragScoreWeights=1.0,1.0",sep=" ")
  command_metfrag<-gsub(x = command_metfrag,pattern = "[database]",replacement = database,fixed = T)
  command_metfrag<-paste(command_metfrag,local_db)
  command_metfrag<-gsub(x = command_metfrag,pattern = "MetFragScoreTypes=FragmenterScore",replacement = "MetFragScoreTypes=FragmenterScore,OfflineMetFusionScore",fixed = T)
  command_metfrag<-paste(command_metfrag," ResultsFile=",paste(outDir,basename(par_file),sep = "/"),sep = "")


  out_metfrag<-system2(conda_path, c(main_params,"metfrag",
                        shQuote(command_metfrag)),stdout =T ,wait = T,stderr = T,timeout = timeout)

  # checked_file<-T
  # number_of_checks<-0
  # while((checked_file & !file.exists(paste(outDir,basename(par_file),sep = "/"))) | timeout==0)
  # {
  #   number_of_checks<-number_of_checks+chech_file_interval
  #   Sys.sleep(time = chech_file_interval)
  #   # if(file.exists(paste(outDir,paste(basename(par_file),".log",sep = ""),sep = "/")))
  #   # {
  #   #   tmp<-readLines((paste(outDir,paste(basename(par_file),".log",sep = ""),sep = "/")))
  #   #   if(any(grepl(pattern = "Stored",x = tmp,fixed = F)))
  #   #   {
  #   #     checked_file<-F
  #   #   }
  #   # }
  #   if(number_of_checks>timeout)
  #   {
  #     checked_file<-T
  #   }
  # }
  # Sys.sleep(time = chech_file_interval)

  data_res<-NA

  if(file.exists(paste(outDir,basename(par_file),sep = "/")))
  {
    data_res<-read.csv(paste(outDir,basename(par_file),sep = "/"))
    if(nrow(data_res)>0)
    {
      file_info<-strsplit(basename(par_file),split = "_",fixed = T)[[1]]
      data_res$parentRT<-file_info[2]
      data_res$parentMZ<-file_info[3]
      data_res$fileName<-paste(file_info[4:length(file_info)],collapse  = "_")
      if(!is.na(results_folder))
      {
        write.csv(data_res,paste(results_folder,basename(par_file),sep = "/"))
      }
    }
  }else{
    if(verbose)cat(out_metfrag)
  }
  if(progress_bar==TRUE)
  p(sprintf("processing=%s", par_file))
  data_res
  }
)



#future:::ClusterRegistry("stop")

number_if_success<-sum(unlist(sapply(results,nrow))>0)

if(length(number_if_success)>0)
{
  return(do.call(rbind,results[!is.na(results)]))
}else{
  return(NA)
}

}
