#' Perform identification using CFM-ID
#'
#' This function allows you to perform identification using CFM-ID
#' Please note that you need to have CFM-ID, e.g using \code{\link{install_tools}} only on Linux or IOS.
#' For Windows see the details
#'
#' We install CFM-ID in metaboraid_package environment.
#'
#'
#'
#' @param parameter_zip_files A zip file containing MS2 parameter generated by \code{\link{map_adducts}}
#' @param database Name of the database to use: Only one of KEGG, PubChem, ChemSpider, and LocalCSV!
#' @param local_database absolute path to the local database (CSV). See the details
#' @param ncores Number of cores to use for parallel processing. Default 1
#' @param progress_bar Whether to show progress bar or not. Default FALSE
#' @param verbose Show information about different stages of the processes. Default FALSE
#' @param conda Conda binary to use. Default auto
#' @param env conda environment used to run the process. Default metaboraid_package
#' @param results_folder a path to a folder where results for EACH ion will be returned
#' @param max_number_of_compound Maximum number of compounds to report for each ion. Default 100
#' @param chech_file_interval not used
#' @param total_check_time not used
#' @param timeout The maximum number of seconds to wait for a single out to give a result. Default 600
#' @param cfm_bin An absolute path to the a cfm-id binary. Used on Windows. For other platform use conda
#' @export
#' @details The local CSV file must contain the metabolites you wish to perform identification on.
#' this file must contain the following columns: "Identifier",  "MonoisotopicMass" ,"MolecularFormula" ,"SMILES"        ,   "InChI"         ,   "InChIKey1"     ,   "InChIKey2"    ,    "InChIKey3"    ,    "Name"         ,    "InChIKey".
#' An example of such dataset for HMDB can be found here: \url{https://github.com/metaboraid/test-datasets/blob/master/hmdb_2017-07-23.csv}
#'
#' If you are running on Windows, you need to install CFM-ID yourself (see \url{https://cfmid.wishartlab.com/})
#' After installation, find the aboslute path for the cfm-id binary file (cfm-id.exe) and set cfm_bin to the path.
#'
#' @examples
#'
#' library(CAMERA)
#' library(metaboraid)
#' # Read MS1 and MS2 files
#' ms1_files<-system.file("ms1data",c("X1_Rep1.mzML","X2_Rep1.mzML"),package = "metaboraid")
#' ms2_files<-system.file("ms2data",c("sample1.mzML","sample2.mzML"),package = "metaboraid")
#'
#' # mass trace detection
#' xs <- xcmsSet(ms1_files,method="centWave",ppm=30,peakwidth=c(5,10))
#'
#' # mass trace matching
#' xsg <- group(xs)
#'
#' # convert to CAMERA
#' xsa <- xsAnnotate(xsg)
#'
#' # Group mass traces
#' anF <- groupFWHM(xsa, perfwhm = 0.6)
#'
#' # Detect isotopes
#' anI <- findIsotopes(anF, mzabs = 0.01)
#'
#' # Group using correlation
#' anIC <- groupCorr(anI, cor_eic_th = 0.75)
#'
#' # Find adducts
#' anFA <- findAdducts(anIC, polarity="positive")
#'
#' # map features and MS2s
#' mapped_features<-map_features(inputMS2s = ms2_files,input_camera = anFA,ppm = 10,rt = 10)
#'
#' # Map adducts
#' mapped_adducts<-map_adducts(inputMS2List=mapped_features,input_camera=anFA,
#'                             precursorppm=10,
#'                             fragmentppm=20,fragmentabs=0.01,minPrecursorMass=NA,maxPrecursorMass=NA,
#'                             minPeaks=10,maxSpectra=10,mode="pos",adductRules="primary",
#'                             outputDir="general_parameters_4",searchMultipleChargeAdducts=T,
#'                             includeMapped=T,includeUnmapped=F,verbose=T)
#'
#' # Run the search
#'
#' run_cfm("parameter_files.zip",database = "KEGG",ncores = 2,progress_bar = F,verbose = T,results_folder = "pp",chech_file_interval = 2,timeout = 600,conda = "auto",max_number_of_compound=10)
#'
#' @return
#' A dataframe containing the identified ions. The dataframe contains search engine and database specific information but also tree important columns: parentMZ, parentRT, fileName which are used to trace the ions by the downstream processes.
#' @import reticulate
#' @import zip
#' @import parallel
#' @import future
#' @import progressr
#' @import future.apply
#' @import utils
#'
#'
run_cfm<-function(parameter_zip_files=NA,local_database=NA,ncores=1,progress_bar=T,verbose=F,conda = "auto",env="metaboraid_package_cfm",results_folder=NA,max_number_of_compound=100,
                      chech_file_interval=2,total_check_time=20,timeout=600,cfm_bin=NA){
  if(verbose)cat("\nChecking software ...","\n")
  tool_name<-""
if(is.na(cfm_bin)|is.null(cfm_bin)){
  check_if_conda_is_installed(env,conda=conda)
  check_out<-suppressWarnings(check_if_software_exist("cfm-id",conda=conda,env = env))
  if(length(check_out)==1 && check_out==1)
  {
    stop("We did not find metfrag! Please try installing the tools first!")
  }

  conda_path<-reticulate::conda_binary(conda)

  main_params<-c("run","-n",env)
  tool_name<-"cfm-id"
}else if(file.exists(cfm_bin)){

  out <- suppressWarnings(system2(cfm_bin,stdout = T,stderr = T))


  if(!any(grepl("Usage: cfm-id",out)))
  {
    stop("We did not find cfm-id! Please try installing the tools first!")
  }
  main_params<-""
  conda_path<-cfm_bin
  tool_name<-""
}else{
  stop(sprintf("We did not find this %s!",cfm_bin))
}


  if(verbose)cat("\nChecking database ...","\n")
  local_db<-""

    if(is.na(local_database))stop("You need to provide a path to a CSV dataset")
    if(!file.exists(local_database)){
      stop(sprintf("We did not find %s! Please check the path!",local_database))
    }

    tmp<-read.csv(local_database)
    data_Base_col_names<-c( "Identifier",  "MonoisotopicMass" ,"MolecularFormula" ,"SMILES"        ,   "InChI"         ,   "InChIKey1"     ,   "InChIKey2"    ,    "InChIKey3"    ,    "Name"         ,    "InChIKey" )
    if(!all(data_Base_col_names%in%colnames(tmp))){

      stop(sprintf("The following columns are missing from your database file: %s!",paste(data_Base_col_names[!data_Base_col_names%in%colnames(tmp)],collapse = ",")))
    }
    local_db<-paste("LocalDatabasePath=",local_database,sep = "")



  if(is.na(parameter_zip_files) | is.null(parameter_zip_files))
  {
    stop("parameter_zip_files is missing!")
  }else{
    if(!file.exists(parameter_zip_files)){
      stop(sprintf("We could not find %s! Check parameter_zip_files!",parameter_zip_files))
    }
  }

    if(any(is.na(max_number_of_compound)) | any(is.null(max_number_of_compound)))
    {
      stop("No max_number_of_compound input have been provided!")
    }else if(max_number_of_compound<-1 | max_number_of_compound==0){
      stop("max_number_of_compound must be equal to -1 or greater than 0!")
    }

  if(verbose)cat("\nPreparing cfm-id ...","\n")


  tmpDir<-createTmpDir("cfm_")
  do.call(file.remove, list(list.files(tmpDir, full.names = TRUE,recursive = T)))
  zip::unzip(parameter_zip_files,junkpaths = T,exdir = tmpDir)
  all_params<-list.files(tmpDir,full.names = T)


  tmpDir2<-tmpDir
  outDir<-paste(tmpDir2,"cfm_res",sep = "/")
  dir.create(outDir)



  library(doFuture)
  if(is.na(ncores)|is.null(ncores))
  {
    stop("ncores must be a number higher than 1!")
  }
  if(ncores>1)
  {
    if(verbose)cat("Running cfm-id in parallel...","\n")
    cl <- parallel::makeCluster(ncores, type = "PSOCK")
    plan(future::cluster, workers = cl)
  }else{
    if(verbose)cat("Running cfm-id sequencial ...","\n")
    plan(sequential)
  }

  if(!is.numeric(timeout))
  {
    stop("timeout must be numberic!")
  }else if(timeout<0){
    stop("timeout must be equal or greater than than 0!")
  }

  if(!is.numeric(chech_file_interval))
  {
    stop("chech_file_interval must be numberic!")
  }else if(chech_file_interval<0){
    stop("chech_file_interval must be equal or greater than than 0!")
  }
  if(timeout<=chech_file_interval)
  {
    stop("timeout must be greater than chech_file_interval!")
  }

  if(is.na(progress_bar) | is.null(progress_bar))
  {
    stop("progress_bar must be a logical value!")
  }
  if(!is.logical(progress_bar))
  {
    stop("progress_bar must be a logical value!")
  }

  if(verbose)cat("Downloading model files ...","\n")


  pos_dir<-paste(tmpDir2,"pos_model",sep = "/")
  dir.create(pos_dir)
  utils::download.file("https://raw.githubusercontent.com/metaboraid/cfm-id-models/main/pos/param_config.txt",destfile = paste(pos_dir,"param_config.txt",sep = "/"),quiet = !verbose
  )
  utils::download.file("https://raw.githubusercontent.com/metaboraid/cfm-id-models/main/pos/param_output0.log",destfile = paste(pos_dir,"param_output0.log",sep = "/"),quiet = !verbose
  )
  logFile_pos<-paste(pos_dir,"param_output0.log",sep = "/")
  ModelFilfe_pos<-paste(pos_dir,"param_config.txt",sep = "/")

  neg_dir<-paste(tmpDir2,"neg_model",sep = "/")
  dir.create(neg_dir)
  utils::download.file("https://raw.githubusercontent.com/metaboraid/cfm-id-models/main/neg/param_config.txt",destfile = paste(neg_dir,"param_config.txt",sep = "/"),quiet = !verbose
  )
  utils::download.file("https://raw.githubusercontent.com/metaboraid/cfm-id-models/main/neg/param_output0.log",destfile = paste(neg_dir,"param_output0.log",sep = "/"),quiet = !verbose)

  logFile_neg<-paste(neg_dir,"param_output0.log",sep = "/")
  ModelFilfe_neg<-paste(neg_dir,"param_config.txt",sep = "/")



  #
  # if(!is.numeric(total_check_time))
  # {
  #   stop("total_check_time must be numberic!")
  # }else if(total_check_time<0){
  #   stop("total_check_time must be equal or greater than than 0!")
  # }


  results<-NA
  if(!is.na(results_folder))
  {
    dir.create(results_folder)
  }

  if(progress_bar==TRUE)
    p <- progressr::progressor(along =  all_params)

  library(future.apply)
  results<-  future_lapply(all_params,function(par_file) {

    command_cfm<-readLines(par_file)
    splitParams<-strsplit(command_cfm,split = " ",fixed = T)

    ppmIndex<-sapply(splitParams,FUN =  function(x){grep(x,pattern = "FragmentPeakMatchRelativeMassDeviation",fixed=T)})
    ppm<-as.numeric(strsplit(splitParams[[1]][[ppmIndex]],split = "=",fixed=T)[[1]][[2]])

    ppmIndex<-sapply(splitParams,FUN =  function(x){grep(x,pattern = "DatabaseSearchRelativeMassDeviation",fixed=T)})
    ppmPrecursor<-as.numeric(strsplit(splitParams[[1]][[ppmIndex]],split = "=",fixed=T)[[1]][[2]])

    absDevIndex<-sapply(splitParams,FUN =  function(x){grep(x,pattern = "FragmentPeakMatchAbsoluteMassDeviation",fixed=T)})
    absDev<-as.numeric(strsplit(splitParams[[1]][[absDevIndex]],split = "=",fixed=T)[[1]][[2]])

    compound<-basename(par_file)
    parentmass<-as.numeric(strsplit(compound,split = "_",fixed = T)[[1]][3])

    ionization<-""
    ionizationIndex<-sapply(splitParams,FUN =  function(x){grep(x,pattern = "PrecursorIonType",fixed=T)})
    ionization<-as.character(strsplit(splitParams[[1]][[ionizationIndex]],split = "=",fixed=T)[[1]][[2]])

    polarity<-gsub(pattern = "\\[(.*?)\\]",replacement = "",x =ionization ,fixed = F)

    collision<-""
    collisionIndex<-sapply(splitParams,FUN =  function(x){grep(x,pattern = "PeakListString",fixed=T)})
    collision<-as.character(strsplit(splitParams[[1]][[collisionIndex]],split = "=",fixed=T)[[1]][[2]])
    collision<-gsub(pattern = "_",replacement = " ",x = collision,fixed=T)
    collision<-gsub(pattern = ";",replacement = "\n",x = collision,fixed=T)

    NeutralPrecursorMass<-""
    NeutralPrecursorMassIndex<-sapply(splitParams,FUN =  function(x){grep(x,pattern = "NeutralPrecursorMass",fixed=T)})
    NeutralPrecursorMass<-as.character(strsplit(splitParams[[1]][[NeutralPrecursorMassIndex]],split = "=",fixed=T)[[1]][[2]])
    NeutralPrecursorMass<-as.numeric(NeutralPrecursorMass)

    mzdeviation = (ppmPrecursor*NeutralPrecursorMass)/1000000
    mass_upper = NeutralPrecursorMass+mzdeviation
    mass_lower = NeutralPrecursorMass-mzdeviation



    toCFM0<-paste("energy0","\n",collision,"\n",sep = "")
    toCFM1<-paste("energy1","\n",collision,"\n",sep = "")
    toCFM2<-paste("energy2","\n",collision,"\n",sep = "")
    toCFM<-paste(toCFM0,toCFM1,toCFM2,sep = "")



    if(polarity=="+")
    {

      ModelFilfe<-ModelFilfe_pos
      logFile<-logFile_pos
    }else if(polarity=="-"){
      ModelFilfe<-ModelFilfe_neg
      logFile<-logFile_neg
    }


    if(is.na(ModelFilfe) | is.na(logFile))
    {
      stop("Something wrong with the polarity")
    }

    if(!file.exists(logFile))
    {
      stop("CFM-ID logFile does not exist")
    }


    local_dir<-paste(outDir,basename(par_file),sep = "/")
    dir.create(local_dir)

    writeLines(toCFM,paste(local_dir,"toCFM.txt",sep="/"))

    inpitToCFMFile<-paste(local_dir,"toCFM.txt",sep="/")

    cfm_folder<-paste(local_dir,"cfm",sep="/")
    dir.create(cfm_folder)


    outputFileTMP<-paste(outDir,basename(par_file),basename(par_file),sep = "/")

    dir.create(paste(cfm_folder,"database",sep = "/"))
    inpitToCFMFileDatabase<-paste(cfm_folder,"database","databaseFile.txt",sep = "/")
    candidateFile<-read.csv(local_database)
    candidateFile<-na.omit(candidateFile)
    limitCandiateFile<-candidateFile[,"MonoisotopicMass"]>=mass_lower & candidateFile[,"MonoisotopicMass"]<mass_upper
    candidateFile<-candidateFile[limitCandiateFile==T,]
    write.table(candidateFile[,c("Identifier","SMILES")],file = inpitToCFMFileDatabase,sep = " ",
                row.names = F,quote = F,col.names = F)

    emptyDataset<-nrow(candidateFile)<1
    out_cfm<-"no IDs\n"
    if(!nrow(candidateFile)<1)
    {
    toCFMCommand<-paste(" ",inpitToCFMFile," IDTMP ", inpitToCFMFileDatabase, " ",
                        max_number_of_compound, " ",ppmPrecursor, " ",ppm," ", absDev, " ", logFile, " ", ModelFilfe," ",
                        "Jaccard"," 1 ",outputFileTMP,sep="")


    out_cfm<-system2(conda_path, c(main_params,tool_name,
                                      (toCFMCommand)),stdout =T ,wait = T,stderr = T,timeout = timeout)
    }
    # checked_file<-T
    # number_of_checks<-0
    # while((checked_file & !file.exists(paste(outDir,basename(par_file),sep = "/"))) | timeout==0)
    # {
    #   number_of_checks<-number_of_checks+chech_file_interval
    #   Sys.sleep(time = chech_file_interval)
    #   # if(file.exists(paste(outDir,paste(basename(par_file),".log",sep = ""),sep = "/")))
    #   # {
    #   #   tmp<-readLines((paste(outDir,paste(basename(par_file),".log",sep = ""),sep = "/")))
    #   #   if(any(grepl(pattern = "Stored",x = tmp,fixed = F)))
    #   #   {
    #   #     checked_file<-F
    #   #   }
    #   # }
    #   if(number_of_checks>timeout)
    #   {
    #     checked_file<-T
    #   }
    # }
    # Sys.sleep(time = chech_file_interval)

    data_res<-NA

    if(file.exists(outputFileTMP) & emptyDataset==FALSE)
    {
      data_res<-read.table(file = outputFileTMP,header = F,sep = " ",quote = "",check.names = F,stringsAsFactors = F,comment.char = "")
      colnames(data_res)<-c("IndexCFM",paste("Jaccard","Score",sep="_"),"Identifier","SMILES")
      if(nrow(data_res)>0)
      {
        data_res<- merge.data.frame(data_res,candidateFile,by = c("Identifier","SMILES"))
        data_res<-data_res[order(data_res[,"IndexCFM"],decreasing = F),]

        file_info<-strsplit(basename(par_file),split = "_",fixed = T)[[1]]
        data_res$parentRT<-file_info[2]
        data_res$parentMZ<-file_info[3]
        data_res$fileName<-paste(file_info[4:length(file_info)],collapse  = "_")
        data_res$ionization<-ionization
        if(!is.na(results_folder))
        {
          write.csv(data_res,paste(results_folder,basename(par_file),sep = "/"))
        }
      }
    }else{
      if(verbose)cat(out_cfm)
    }
    if(progress_bar==TRUE)
      p(sprintf("processing=%s", par_file))
    data_res
  }
  )

  number_if_success<-sum(unlist(sapply(results,nrow))>0)

  if(length(number_if_success)>0)
  {
    return(do.call(rbind,results[!is.na(results)]))
  }else{
    return(NA)
  }

}

